{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_LAB4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPYnvgJ+2d+BlDHKtuTfs9l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nikunjbansal99/NLP_Lab/blob/main/NLP_LAB4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNIwPDcKiru_"
      },
      "source": [
        "![TITLE.JPG](data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEAeAB4AAD/4RD0RXhpZgAATU0AKgAAAAgABAE7AAIAAAAOAAAISodpAAQAAAABAAAIWJydAAEAAAAcAAAQ0OocAAcAAAgMAAAAPgAAAAAc6gAAAAgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAE5pa3VuaiBiYW5zYWwAAAWQAwACAAAAFAAAEKaQBAACAAAAFAAAELqSkQACAAAAAzgxAACSkgACAAAAAzgxAADqHAAHAAAIDAAACJoAAAAAHOoAAAAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAyMDIwOjA5OjA5IDIxOjE4OjIwADIwMjA6MDk6MDkgMjE6MTg6MjAAAABOAGkAawB1AG4AagAgAGIAYQBuAHMAYQBsAAAA/+ELIGh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8APD94cGFja2V0IGJlZ2luPSfvu78nIGlkPSdXNU0wTXBDZWhpSHpyZVN6TlRjemtjOWQnPz4NCjx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iPjxyZGY6UkRGIHhtbG5zOnJkZj0iaHR0cDovL3d3dy53My5vcmcvMTk5OS8wMi8yMi1yZGYtc3ludGF4LW5zIyI+PHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9InV1aWQ6ZmFmNWJkZDUtYmEzZC0xMWRhLWFkMzEtZDMzZDc1MTgyZjFiIiB4bWxuczpkYz0iaHR0cDovL3B1cmwub3JnL2RjL2VsZW1lbnRzLzEuMS8iLz48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOnhtcD0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wLyI+PHhtcDpDcmVhdGVEYXRlPjIwMjAtMDktMDlUMjE6MTg6MjAuODA1PC94bXA6Q3JlYXRlRGF0ZT48L3JkZjpEZXNjcmlwdGlvbj48cmRmOkRlc2NyaXB0aW9uIHJkZjphYm91dD0idXVpZDpmYWY1YmRkNS1iYTNkLTExZGEtYWQzMS1kMzNkNzUxODJmMWIiIHhtbG5zOmRjPSJodHRwOi8vcHVybC5vcmcvZGMvZWxlbWVudHMvMS4xLyI+PGRjOmNyZWF0b3I+PHJkZjpTZXEgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj48cmRmOmxpPk5pa3VuaiBiYW5zYWw8L3JkZjpsaT48L3JkZjpTZXE+DQoJCQk8L2RjOmNyZWF0b3I+PC9yZGY6RGVzY3JpcHRpb24+PC9yZGY6UkRGPjwveDp4bXBtZXRhPg0KICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgIAogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgCiAgICAgICAgICAgICAgICAgICAgICAgICAgICA8P3hwYWNrZXQgZW5kPSd3Jz8+/9sAQwAHBQUGBQQHBgUGCAcHCAoRCwoJCQoVDxAMERgVGhkYFRgXGx4nIRsdJR0XGCIuIiUoKSssKxogLzMvKjInKisq/9sAQwEHCAgKCQoUCwsUKhwYHCoqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioqKioq/8AAEQgAcwD7AwEiAAIRAQMRAf/EAB8AAAEFAQEBAQEBAAAAAAAAAAABAgMEBQYHCAkKC//EALUQAAIBAwMCBAMFBQQEAAABfQECAwAEEQUSITFBBhNRYQcicRQygZGhCCNCscEVUtHwJDNicoIJChYXGBkaJSYnKCkqNDU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6g4SFhoeIiYqSk5SVlpeYmZqio6Slpqeoqaqys7S1tre4ubrCw8TFxsfIycrS09TV1tfY2drh4uPk5ebn6Onq8fLz9PX29/j5+v/EAB8BAAMBAQEBAQEBAQEAAAAAAAABAgMEBQYHCAkKC//EALURAAIBAgQEAwQHBQQEAAECdwABAgMRBAUhMQYSQVEHYXETIjKBCBRCkaGxwQkjM1LwFWJy0QoWJDThJfEXGBkaJicoKSo1Njc4OTpDREVGR0hJSlNUVVZXWFlaY2RlZmdoaWpzdHV2d3h5eoKDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uLj5OXm5+jp6vLz9PX29/j5+v/aAAwDAQACEQMRAD8A+kaKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKKKKACiiigAooooAKK+f8A9pDxd4g0HVtGs9D1i806Ga3eSQWkxiLMGAGWXB/WuZ+BPjfxRqnxRs9N1TxBqN9ZzxTGSG7uWmBIjJH3iccgdKAPqaiiigAooqO4nitbaW4uHEcUSF3c9FUDJP5UASUV8S+JPiv4u1rxFe31r4j1aytpZ3aC3t7t4lijJ+VcKQOBgZp3hn4s+LtE8RWV7d+ItUvrWOZDPb3V28yyR5+ZcMT1GeaAPtiimQzR3EEc0Dh4pFDo69GBGQafQAUVwfxo17UfDnwq1O/0a5a1u90UazJ95A0igkHscEjNfJv/AAsLxp/0N+vf+DOb/wCKoA+7qK+Ef+FheNP+hv17/wAGc3/xVaulfGPx9pEyPD4lu7gL1S8InDD0O/J/XNAH2zRXlHwl+NUHj6Y6RrFvHY60iF1EZ/d3IHUqDyCOu3njnPXHq9ABRRRQAUUUUAFFc7488XWvgfwbe63dbWaFdtvET/rZTwi/nyfYE9q+PL74oeOdQumnm8V6tGzEnbb3bwqPoqEAUAfctFfH3wx+InjCX4kaHZXPiTU7q2ur2OKaK6uWmV1YgEfOTj8K+waACiiigAooooAKKKKACiiigD5n/am/5GbQf+vOT/0OuU/Z7/5LNpv/AFxn/wDRTV1f7U3/ACM2g/8AXnJ/6HXKfs9/8lm03/rjP/6KagD7DooooAK81+PXib/hHfhXexRPtudUYWUeDztYEuf++Aw/EV6VXyv+0v4lOpeOrXQ4ZMw6VbgyKD/y1kwx/Jdn5mgDzjwJ4Ybxj450vQwWWO6m/fOvVY1BZyPfaDj3xWTqunT6PrF5pt4u24s53gkHoysQf5V7n+y74b87VNX8STJ8tvGLOAn+82Gf8QAv/fVc3+0Z4b/sb4mHUoU22+rwLOCBx5i/I4/RW/4FQB7d8B/E3/CRfCuxjlk33WmE2UuTzheU/wDHCo/A16RXyx+zR4m/s3xxd6FM+IdWg3Rgn/lrHlh+al/yFfU9AHmX7Qn/ACRnUv8ArtB/6NWvkSwVX1K2VwGVpkBBGQRkV9d/tCf8kZ1L/rtB/wCjVr5DspFh1C3kkOESVWY46AGgD7mb4eeC2Ug+EdCwRjjTYR/7LXg/7QXwx0Twrp9j4h8OWy2Mdxc/Zri2QnZuKFlZR/DwjAgcdOnOfVz8e/hsFJHiPPsLG45/8h14f8bfi5Z+PxaaToEUy6XZymZppl2meTBUEL2ABbryd3QY5AOE8AXs+nfEbw9c2rlJF1GAZ9QXAYfQgkfjX3fXyN8CvhzfeJvGNnrt3bPHo2mSiczOuFnlU5VF9cMAT2AGO4r65oAKKKKACiivP/jJ49HgTwLNJaybdUv829kAeVJHzSf8BBz9SvrQB4X+0F4+/wCEn8Y/2Jp8u7TdHZoyVPEs/R299v3R9G9a5C98EzaZ8LLLxVfB431LUBBaxnj9yqOS5/3mAx7LnvTfhx4MuPHvje00lN4t8+deTD/lnCCNxz6nIA9yK9w/aXtILD4c6DaWcSw29vfLHFGgwEURMAB9BQB4f8Lv+SreGv8AsJQ/+hCvuWvhr4Xf8lW8Nf8AYSh/9CFfctABRRRQAUUUUAFFFFABRRRQB8z/ALU3/IzaD/15yf8Aodcp+z3/AMlm03/rjP8A+imrq/2pv+Rm0H/rzk/9DrlP2e/+Szab/wBcZ/8A0U1AH2HRRRQBBf3sGm6bc314+y3tYmmlb+6qgkn8hXwP4g1ibxD4j1DV7r/W31w87DP3dxJA+gHH4V9VftDeJv7C+GMthC2LjWJRbLjqIx8zn8gF/wCBV8iUAfa3wa8N/wDCMfCvSbeRNlxdR/bJ+Od0nIB9wu0fhXOftIeHf7X+Gy6pFHun0i4WUkdRE/yOPzKH/gNfJlFAGl4e1mfw74k0/WLQnzbK4SZQDjdtOSv0IyPxr73sbyDUdPt72zcSW9zEs0Tj+JWAIP5Gvz2r67/Z58Tf278MYrCZs3Gjym2bPUxn5kP5Er/wGgCx+0J/yRnUv+u0H/o1a+Po42mlSOMZd2CqM9Sa+wf2hP8AkjOpf9doP/Rq18i6d/yFLT/rsn/oQoA7v/hQvxJ/6Fv/AMnrb/45XM+I/BHiXwlsPiLRrqxRztWV13RsfQOuVzx0zX3lWL4x0uy1nwXq9hqiq1rLaSbyw+5hSQ31BAI9xQB8n/D/AONHiTwXe28Nzdzano6kLJZzvuKJ/wBM2PKkdh09u9fXdprVjf8Ah+LWrSbzLGW3Fykg7pt3dPXHavz+r7D+BIOofA7Tra7ZpI2+0Q8/3DI4x+poA4Z/2rFDts8HErn5SdTwSPp5VN/4at/6k3/yqf8A2mnP+ympdtnjEhc/KDpmSB9fNpv/AAyl/wBTl/5S/wD7dQB6j8MPiVD8SNAu9RGnnTHtJ/KkiacSjG0MG3bV9T27V8vfFvx03jzx3c3kLk6da5t7Je3lg8v9WOT9MDtX0X4b+HCfDT4W+JbG31F9RuLm3uJzOIfKwfJIVQu5umPXvXx8jtG6ujFWU5VgcEH1oA+wfgZ4A/4QzwSt3fw7NW1ULPPuHzRJj5I/bAOT7sR2rnf2o/8AkRdH/wCwl/7SevAP+FheNP8Aob9e/wDBnN/8VVHVPE+v65AkGt65qWoxRtvSO7u5JVVsYyAxODg9aANf4Xf8lW8Nf9hKH/0IV9y1+etrdXFjdxXVlPLb3ELB45oXKOjDoQRyD719Cfs3eK/EOueItZtNa1a/1K3S1SRTeXDzeW+/AwWJxkE9PSgD6GooooAKKKKACiiigAooooA+Z/2pv+Rm0H/rzk/9Dry74e+Mf+ED8Z22v/Yft/kJInked5W7cpX721umfSvqT4p/CK2+JclhOdVk0y6s1ZBIIPOV0Yg4K7l5BHXPc155/wAMpf8AU5f+Uv8A+3UAH/DVv/Um/wDlU/8AtNaGg/tNx6x4i0/TJ/CrWyXlzHAZl1DzDHvYLnb5Yz19RWf/AMMpf9Tl/wCUv/7dWhoH7MkWjeItO1OfxU11HZ3MdwYF0/yzJsYNt3eYcZx6UAcJ+0d4l/tn4kLpcL7rfR4BFgdPNfDOfy2D/gNaP7Mfhw33jLUNelTMWm2/lREj/lrJxkfRAw/4EK63xF+zQuveJdQ1ZfFskP265kuDHLYeYVLMWxu8xc9fSvSPhx8P7L4c+G30uzuXvJJpjPPcOgUuxAAwOcAADjJ7+tAHW0UUUAfHv7QHhv8AsD4qXdxEm231WNbxMDjceHH13KT/AMCFX/2cfEv9jfEhtLmfbb6xAYsHp5qZZD+W8f8AAq92+KPwrs/iZaWIlv2066sWfy51hEmVbGVK5GeVBHPHPrXDeHf2aBoXiTT9WPi6SU2NwlwqR2HllirBgN3mHHT0oA6n9oT/AJIzqX/XaD/0atfINtN9nuoptu7y3D4zjODmvuzxv4StfHHhG80G9mkt0udpWaMZMbKwYHHfkdK8W/4ZS/6nL/yl/wD26gA/4at/6k3/AMqn/wBprkPHn7QGu+MtFm0ixsYtHsrgFbjy5TLJKv8Ac3YACnvgc/TIrr/+GUv+py/8pf8A9urR039lrRoZFOreIr67UdVt4Ehz+ZegD530LQtR8S61b6Vo1s9zd3DhURRwOfvE9lHcnpX3L4O8Nw+EfB2m6FbtvWyhCM4GN7klnbHuxJ/GofCngXw74JtGg8OabHalxiSYkvJJ/vOeT9OntXQUAFFFFAAQGUhhkHgg9654/D7wYxJPhHQiTySdNh5/8droaKAOd/4V74L/AOhQ0H/wWQ//ABNePftHeGNA0PwbpU+iaHpunSyX+x5LS0jiZl8tjglQMjI6V9B1xvxM+HcHxI8PQabPqEmnvbz+fHMkYkGdpXBXIyOfUUAfI/w4tbe++Jnh61vYIri3mv4kkhmQOjqWGQQeCPavtnSvD2i6D5v9h6RYab52PN+x2yQ78ZxnaBnGT19a8j8Ifs4W/hjxVYa1ceJZL02MyzpClkItzLyMku3GfavbaACiiigAooooAKKKKACsbxd4osvBnha71/VIriW1tNnmJbqrOdzqgwGIHVh36Vs1na9oOm+J9DuNI1y2+1WFzt82LzGTdtYMOVII5UHg9qAPKv8Ahp/wX/0DNe/8B4f/AI7R/wANP+C/+gZr3/gPD/8AHa6L/hQvw2/6Fv8A8nrn/wCOUf8AChfht/0Lf/k9c/8AxygDnf8Ahp/wX/0DNe/8B4f/AI7R/wANP+C/+gZr3/gPD/8AHa6L/hQvw2/6Fv8A8nrn/wCOUf8AChfht/0Lf/k9c/8AxygDnf8Ahp/wX/0DNe/8B4f/AI7R/wANP+C/+gZr3/gPD/8AHa6L/hQvw2/6Fv8A8nrn/wCOUf8AChfht/0Lf/k9c/8AxygDnf8Ahp/wX/0DNe/8B4f/AI7R/wANP+C/+gZr3/gPD/8AHa6L/hQvw2/6Fv8A8nrn/wCOUf8AChfht/0Lf/k9c/8AxygDnf8Ahp/wX/0DNe/8B4f/AI7R/wANP+C/+gZr3/gPD/8AHa6L/hQvw2/6Fv8A8nrn/wCOUf8AChfht/0Lf/k9c/8AxygDnf8Ahp/wX/0DNe/8B4f/AI7R/wANP+C/+gZr3/gPD/8AHa6L/hQvw2/6Fv8A8nrn/wCOUf8AChfht/0Lf/k9c/8AxygDnf8Ahp/wX/0DNe/8B4f/AI7R/wANP+C/+gZr3/gPD/8AHa6L/hQvw2/6Fv8A8nrn/wCOUf8AChfht/0Lf/k9c/8AxygDnf8Ahp/wX/0DNe/8B4f/AI7R/wANP+C/+gZr3/gPD/8AHa6L/hQvw2/6Fv8A8nrn/wCOUf8AChfht/0Lf/k9c/8AxygDnf8Ahp/wX/0DNe/8B4f/AI7R/wANP+C/+gZr3/gPD/8AHa6L/hQvw2/6Fv8A8nrn/wCOUf8AChfht/0Lf/k9c/8AxygDnf8Ahp/wX/0DNe/8B4f/AI7R/wANP+C/+gZr3/gPD/8AHa6L/hQvw2/6Fv8A8nrn/wCOUf8AChfht/0Lf/k9c/8AxygDnf8Ahp/wX/0DNe/8B4f/AI7R/wANP+C/+gZr3/gPD/8AHa6L/hQvw2/6Fv8A8nrn/wCOUf8AChfht/0Lf/k9c/8AxygDnf8Ahp/wX/0DNe/8B4f/AI7W14R+PHhjxn4ptNA0ux1aK6u9/lvcQxKg2oznJWQnop7dasf8KF+G3/Qt/wDk9c//ABytHQfhH4I8Ma5b6voeifZb+23eVL9rnfbuUqeGcg8MRyO9AHZ0UUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAFFFFABRRRQAUUUUAf//Z)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVqGKG9aYZBl"
      },
      "source": [
        "import nltk\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BWjEd_nhiE2"
      },
      "source": [
        "# **Importing Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPq5MkkxZV4K"
      },
      "source": [
        "para_object = open('lab4_text.txt')\n",
        "input_str = para_object.read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J-P3M0-NulN"
      },
      "source": [
        "input_str = input_str.lower()     # Making all letters lowercase in text."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2hT7x4VN16_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "5dad82da-8c42-4a63-e0bd-14422c8cf47f"
      },
      "source": [
        "input_str"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'i must be honest with you. i was about to go to sleep before i opened my mail and read your letter. now i am wide awake, sitting upright, because you made me question my preferences between shoes and slippers. be patient with me. i need proper peaceful sleep and let’s sort this out.\\n\\n \\n\\n \\n\\ni am a shoe person. correction: i am a person obsessed with dry, dust-free feet. whatever helps me keep a grip on my walk and posture in spite of my profusely sweaty feet, i am that person. whatever keeps the grainy, pokey sensation of soil or sand in parts of my skin away, i am that person. i guess, i am a shoe person because it is loyal to my whole feet. not making parts of it lying exposed and parts of it covered, without any symmetry. i am also cotton sock person, preferably red. sometimes, i am a clean matte (anti-slippery) floor person. basically, i am a person with issues.\\n\\n \\n\\n \\n\\ni really liked your host-guest theory of travelling, how we do not just get out of home when we travel, the home expands when we step foot at a place engulfing it into our comfort zone. but the thing is i wear socks all the time in my house, and open them when i go to bed, replacing the sock with a comforter. i guess i need that comfort zone close and maybe, mine is restricted to my own skin. so much so, that it doesn’t even include my own home. when i travel, i like wearing shoes, with a firm grip on myself, dust free, protected. when i face situations where i have to open them and i don’t want to, i usually wrinkle my nose. it doesn’t get better that i can’t wear those shoes again with a dirty feet. i take a handkerchief.\\n\\n \\n\\n\\nimagine my situation at the beach or in a hill stream, when the water feels soothing to my sweaty feet and removes the dust, only to attract more of it when i walk on the sand. i let it irritate me those times, because i always have the ocean and the river on my side. i like my bare feet drowning with no air bubbles left. i don’t like it when droplets of water make only a part of my feet wet, only to let me realise and miss the comfort of dry skin and scowl at the linger of irritation due to a little dampness. i don’t like it when i have to keep on brushing my left leg against my right to flatten the spheres of water. and repeat it with the right. i just realised why i don’t like drizzling rains.\\n\\n \\n\\n\\neventually, when i have to get out of the water, i give up my fight with the dirt and wear those damn shoes with muddy feet. those are the times i miss my slippery slippers. don’t let my socks or shoes hear me say that. they do not know that sometimes i keep a back-up pair of red flip-flops for such scenarios. does this make me a slipper person? i guess i am a slipper person when my feet are ankle deep in mud, so that there is no place for me to complain. no alternative. no uneasy half-done feeling. otherwise, not much of a slipper person.\\n\\n \\n\\n \\n\\ni am a person who likes symmetry. all in or none at all. it’s difficult being me in this world with its shades of grey. but then, my favourite colour is red and thankfully it covers the entire spectrum. all i need is an emotion, and the rest is taken care of.\\n\\n \\n\\nthank you for being the listener you are. this has been a selfish post. i used your letter for my sense of clarity. you always make me reflect and dig deep. i can finally sleep now. goodnight.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E-mQdyzhaj0"
      },
      "source": [
        "# **Tokenization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvh-hjAlQiXS"
      },
      "source": [
        "### **Word Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0i47A29cNpsG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "47dccd33-6296-417f-8f21-c1da939c3505"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k409BOVKn1A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "85f0ab59-4fb1-4a3c-8635-e7067db35461"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "word_token_reslt = word_tokenize(input_str)\n",
        "print(word_token_reslt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'must', 'be', 'honest', 'with', 'you', '.', 'i', 'was', 'about', 'to', 'go', 'to', 'sleep', 'before', 'i', 'opened', 'my', 'mail', 'and', 'read', 'your', 'letter', '.', 'now', 'i', 'am', 'wide', 'awake', ',', 'sitting', 'upright', ',', 'because', 'you', 'made', 'me', 'question', 'my', 'preferences', 'between', 'shoes', 'and', 'slippers', '.', 'be', 'patient', 'with', 'me', '.', 'i', 'need', 'proper', 'peaceful', 'sleep', 'and', 'let', '’', 's', 'sort', 'this', 'out', '.', 'i', 'am', 'a', 'shoe', 'person', '.', 'correction', ':', 'i', 'am', 'a', 'person', 'obsessed', 'with', 'dry', ',', 'dust-free', 'feet', '.', 'whatever', 'helps', 'me', 'keep', 'a', 'grip', 'on', 'my', 'walk', 'and', 'posture', 'in', 'spite', 'of', 'my', 'profusely', 'sweaty', 'feet', ',', 'i', 'am', 'that', 'person', '.', 'whatever', 'keeps', 'the', 'grainy', ',', 'pokey', 'sensation', 'of', 'soil', 'or', 'sand', 'in', 'parts', 'of', 'my', 'skin', 'away', ',', 'i', 'am', 'that', 'person', '.', 'i', 'guess', ',', 'i', 'am', 'a', 'shoe', 'person', 'because', 'it', 'is', 'loyal', 'to', 'my', 'whole', 'feet', '.', 'not', 'making', 'parts', 'of', 'it', 'lying', 'exposed', 'and', 'parts', 'of', 'it', 'covered', ',', 'without', 'any', 'symmetry', '.', 'i', 'am', 'also', 'cotton', 'sock', 'person', ',', 'preferably', 'red', '.', 'sometimes', ',', 'i', 'am', 'a', 'clean', 'matte', '(', 'anti-slippery', ')', 'floor', 'person', '.', 'basically', ',', 'i', 'am', 'a', 'person', 'with', 'issues', '.', 'i', 'really', 'liked', 'your', 'host-guest', 'theory', 'of', 'travelling', ',', 'how', 'we', 'do', 'not', 'just', 'get', 'out', 'of', 'home', 'when', 'we', 'travel', ',', 'the', 'home', 'expands', 'when', 'we', 'step', 'foot', 'at', 'a', 'place', 'engulfing', 'it', 'into', 'our', 'comfort', 'zone', '.', 'but', 'the', 'thing', 'is', 'i', 'wear', 'socks', 'all', 'the', 'time', 'in', 'my', 'house', ',', 'and', 'open', 'them', 'when', 'i', 'go', 'to', 'bed', ',', 'replacing', 'the', 'sock', 'with', 'a', 'comforter', '.', 'i', 'guess', 'i', 'need', 'that', 'comfort', 'zone', 'close', 'and', 'maybe', ',', 'mine', 'is', 'restricted', 'to', 'my', 'own', 'skin', '.', 'so', 'much', 'so', ',', 'that', 'it', 'doesn', '’', 't', 'even', 'include', 'my', 'own', 'home', '.', 'when', 'i', 'travel', ',', 'i', 'like', 'wearing', 'shoes', ',', 'with', 'a', 'firm', 'grip', 'on', 'myself', ',', 'dust', 'free', ',', 'protected', '.', 'when', 'i', 'face', 'situations', 'where', 'i', 'have', 'to', 'open', 'them', 'and', 'i', 'don', '’', 't', 'want', 'to', ',', 'i', 'usually', 'wrinkle', 'my', 'nose', '.', 'it', 'doesn', '’', 't', 'get', 'better', 'that', 'i', 'can', '’', 't', 'wear', 'those', 'shoes', 'again', 'with', 'a', 'dirty', 'feet', '.', 'i', 'take', 'a', 'handkerchief', '.', 'imagine', 'my', 'situation', 'at', 'the', 'beach', 'or', 'in', 'a', 'hill', 'stream', ',', 'when', 'the', 'water', 'feels', 'soothing', 'to', 'my', 'sweaty', 'feet', 'and', 'removes', 'the', 'dust', ',', 'only', 'to', 'attract', 'more', 'of', 'it', 'when', 'i', 'walk', 'on', 'the', 'sand', '.', 'i', 'let', 'it', 'irritate', 'me', 'those', 'times', ',', 'because', 'i', 'always', 'have', 'the', 'ocean', 'and', 'the', 'river', 'on', 'my', 'side', '.', 'i', 'like', 'my', 'bare', 'feet', 'drowning', 'with', 'no', 'air', 'bubbles', 'left', '.', 'i', 'don', '’', 't', 'like', 'it', 'when', 'droplets', 'of', 'water', 'make', 'only', 'a', 'part', 'of', 'my', 'feet', 'wet', ',', 'only', 'to', 'let', 'me', 'realise', 'and', 'miss', 'the', 'comfort', 'of', 'dry', 'skin', 'and', 'scowl', 'at', 'the', 'linger', 'of', 'irritation', 'due', 'to', 'a', 'little', 'dampness', '.', 'i', 'don', '’', 't', 'like', 'it', 'when', 'i', 'have', 'to', 'keep', 'on', 'brushing', 'my', 'left', 'leg', 'against', 'my', 'right', 'to', 'flatten', 'the', 'spheres', 'of', 'water', '.', 'and', 'repeat', 'it', 'with', 'the', 'right', '.', 'i', 'just', 'realised', 'why', 'i', 'don', '’', 't', 'like', 'drizzling', 'rains', '.', 'eventually', ',', 'when', 'i', 'have', 'to', 'get', 'out', 'of', 'the', 'water', ',', 'i', 'give', 'up', 'my', 'fight', 'with', 'the', 'dirt', 'and', 'wear', 'those', 'damn', 'shoes', 'with', 'muddy', 'feet', '.', 'those', 'are', 'the', 'times', 'i', 'miss', 'my', 'slippery', 'slippers', '.', 'don', '’', 't', 'let', 'my', 'socks', 'or', 'shoes', 'hear', 'me', 'say', 'that', '.', 'they', 'do', 'not', 'know', 'that', 'sometimes', 'i', 'keep', 'a', 'back-up', 'pair', 'of', 'red', 'flip-flops', 'for', 'such', 'scenarios', '.', 'does', 'this', 'make', 'me', 'a', 'slipper', 'person', '?', 'i', 'guess', 'i', 'am', 'a', 'slipper', 'person', 'when', 'my', 'feet', 'are', 'ankle', 'deep', 'in', 'mud', ',', 'so', 'that', 'there', 'is', 'no', 'place', 'for', 'me', 'to', 'complain', '.', 'no', 'alternative', '.', 'no', 'uneasy', 'half-done', 'feeling', '.', 'otherwise', ',', 'not', 'much', 'of', 'a', 'slipper', 'person', '.', 'i', 'am', 'a', 'person', 'who', 'likes', 'symmetry', '.', 'all', 'in', 'or', 'none', 'at', 'all', '.', 'it', '’', 's', 'difficult', 'being', 'me', 'in', 'this', 'world', 'with', 'its', 'shades', 'of', 'grey', '.', 'but', 'then', ',', 'my', 'favourite', 'colour', 'is', 'red', 'and', 'thankfully', 'it', 'covers', 'the', 'entire', 'spectrum', '.', 'all', 'i', 'need', 'is', 'an', 'emotion', ',', 'and', 'the', 'rest', 'is', 'taken', 'care', 'of', '.', 'thank', 'you', 'for', 'being', 'the', 'listener', 'you', 'are', '.', 'this', 'has', 'been', 'a', 'selfish', 'post', '.', 'i', 'used', 'your', 'letter', 'for', 'my', 'sense', 'of', 'clarity', '.', 'you', 'always', 'make', 'me', 'reflect', 'and', 'dig', 'deep', '.', 'i', 'can', 'finally', 'sleep', 'now', '.', 'goodnight', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKmL_FPfQl00"
      },
      "source": [
        "### **Sentence Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRf1bNjhNsZ_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c643e85f-daa4-4969-c18b-5081506ebd71"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sent_token_reslt = sent_tokenize(input_str)\n",
        "print(sent_token_reslt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i must be honest with you.', 'i was about to go to sleep before i opened my mail and read your letter.', 'now i am wide awake, sitting upright, because you made me question my preferences between shoes and slippers.', 'be patient with me.', 'i need proper peaceful sleep and let’s sort this out.', 'i am a shoe person.', 'correction: i am a person obsessed with dry, dust-free feet.', 'whatever helps me keep a grip on my walk and posture in spite of my profusely sweaty feet, i am that person.', 'whatever keeps the grainy, pokey sensation of soil or sand in parts of my skin away, i am that person.', 'i guess, i am a shoe person because it is loyal to my whole feet.', 'not making parts of it lying exposed and parts of it covered, without any symmetry.', 'i am also cotton sock person, preferably red.', 'sometimes, i am a clean matte (anti-slippery) floor person.', 'basically, i am a person with issues.', 'i really liked your host-guest theory of travelling, how we do not just get out of home when we travel, the home expands when we step foot at a place engulfing it into our comfort zone.', 'but the thing is i wear socks all the time in my house, and open them when i go to bed, replacing the sock with a comforter.', 'i guess i need that comfort zone close and maybe, mine is restricted to my own skin.', 'so much so, that it doesn’t even include my own home.', 'when i travel, i like wearing shoes, with a firm grip on myself, dust free, protected.', 'when i face situations where i have to open them and i don’t want to, i usually wrinkle my nose.', 'it doesn’t get better that i can’t wear those shoes again with a dirty feet.', 'i take a handkerchief.', 'imagine my situation at the beach or in a hill stream, when the water feels soothing to my sweaty feet and removes the dust, only to attract more of it when i walk on the sand.', 'i let it irritate me those times, because i always have the ocean and the river on my side.', 'i like my bare feet drowning with no air bubbles left.', 'i don’t like it when droplets of water make only a part of my feet wet, only to let me realise and miss the comfort of dry skin and scowl at the linger of irritation due to a little dampness.', 'i don’t like it when i have to keep on brushing my left leg against my right to flatten the spheres of water.', 'and repeat it with the right.', 'i just realised why i don’t like drizzling rains.', 'eventually, when i have to get out of the water, i give up my fight with the dirt and wear those damn shoes with muddy feet.', 'those are the times i miss my slippery slippers.', 'don’t let my socks or shoes hear me say that.', 'they do not know that sometimes i keep a back-up pair of red flip-flops for such scenarios.', 'does this make me a slipper person?', 'i guess i am a slipper person when my feet are ankle deep in mud, so that there is no place for me to complain.', 'no alternative.', 'no uneasy half-done feeling.', 'otherwise, not much of a slipper person.', 'i am a person who likes symmetry.', 'all in or none at all.', 'it’s difficult being me in this world with its shades of grey.', 'but then, my favourite colour is red and thankfully it covers the entire spectrum.', 'all i need is an emotion, and the rest is taken care of.', 'thank you for being the listener you are.', 'this has been a selfish post.', 'i used your letter for my sense of clarity.', 'you always make me reflect and dig deep.', 'i can finally sleep now.', 'goodnight.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mycMAc-YZVCG"
      },
      "source": [
        "### **Tokenize using Regular Expression**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYMlW39xVrss",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4c5848fd-11ca-4462-dbca-bd690427a06a"
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer \n",
        "t = RegexpTokenizer(r'\\w+')\n",
        "tokens = t.tokenize(input_str) \n",
        "print(tokens) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'must', 'be', 'honest', 'with', 'you', 'i', 'was', 'about', 'to', 'go', 'to', 'sleep', 'before', 'i', 'opened', 'my', 'mail', 'and', 'read', 'your', 'letter', 'now', 'i', 'am', 'wide', 'awake', 'sitting', 'upright', 'because', 'you', 'made', 'me', 'question', 'my', 'preferences', 'between', 'shoes', 'and', 'slippers', 'be', 'patient', 'with', 'me', 'i', 'need', 'proper', 'peaceful', 'sleep', 'and', 'let', 's', 'sort', 'this', 'out', 'i', 'am', 'a', 'shoe', 'person', 'correction', 'i', 'am', 'a', 'person', 'obsessed', 'with', 'dry', 'dust', 'free', 'feet', 'whatever', 'helps', 'me', 'keep', 'a', 'grip', 'on', 'my', 'walk', 'and', 'posture', 'in', 'spite', 'of', 'my', 'profusely', 'sweaty', 'feet', 'i', 'am', 'that', 'person', 'whatever', 'keeps', 'the', 'grainy', 'pokey', 'sensation', 'of', 'soil', 'or', 'sand', 'in', 'parts', 'of', 'my', 'skin', 'away', 'i', 'am', 'that', 'person', 'i', 'guess', 'i', 'am', 'a', 'shoe', 'person', 'because', 'it', 'is', 'loyal', 'to', 'my', 'whole', 'feet', 'not', 'making', 'parts', 'of', 'it', 'lying', 'exposed', 'and', 'parts', 'of', 'it', 'covered', 'without', 'any', 'symmetry', 'i', 'am', 'also', 'cotton', 'sock', 'person', 'preferably', 'red', 'sometimes', 'i', 'am', 'a', 'clean', 'matte', 'anti', 'slippery', 'floor', 'person', 'basically', 'i', 'am', 'a', 'person', 'with', 'issues', 'i', 'really', 'liked', 'your', 'host', 'guest', 'theory', 'of', 'travelling', 'how', 'we', 'do', 'not', 'just', 'get', 'out', 'of', 'home', 'when', 'we', 'travel', 'the', 'home', 'expands', 'when', 'we', 'step', 'foot', 'at', 'a', 'place', 'engulfing', 'it', 'into', 'our', 'comfort', 'zone', 'but', 'the', 'thing', 'is', 'i', 'wear', 'socks', 'all', 'the', 'time', 'in', 'my', 'house', 'and', 'open', 'them', 'when', 'i', 'go', 'to', 'bed', 'replacing', 'the', 'sock', 'with', 'a', 'comforter', 'i', 'guess', 'i', 'need', 'that', 'comfort', 'zone', 'close', 'and', 'maybe', 'mine', 'is', 'restricted', 'to', 'my', 'own', 'skin', 'so', 'much', 'so', 'that', 'it', 'doesn', 't', 'even', 'include', 'my', 'own', 'home', 'when', 'i', 'travel', 'i', 'like', 'wearing', 'shoes', 'with', 'a', 'firm', 'grip', 'on', 'myself', 'dust', 'free', 'protected', 'when', 'i', 'face', 'situations', 'where', 'i', 'have', 'to', 'open', 'them', 'and', 'i', 'don', 't', 'want', 'to', 'i', 'usually', 'wrinkle', 'my', 'nose', 'it', 'doesn', 't', 'get', 'better', 'that', 'i', 'can', 't', 'wear', 'those', 'shoes', 'again', 'with', 'a', 'dirty', 'feet', 'i', 'take', 'a', 'handkerchief', 'imagine', 'my', 'situation', 'at', 'the', 'beach', 'or', 'in', 'a', 'hill', 'stream', 'when', 'the', 'water', 'feels', 'soothing', 'to', 'my', 'sweaty', 'feet', 'and', 'removes', 'the', 'dust', 'only', 'to', 'attract', 'more', 'of', 'it', 'when', 'i', 'walk', 'on', 'the', 'sand', 'i', 'let', 'it', 'irritate', 'me', 'those', 'times', 'because', 'i', 'always', 'have', 'the', 'ocean', 'and', 'the', 'river', 'on', 'my', 'side', 'i', 'like', 'my', 'bare', 'feet', 'drowning', 'with', 'no', 'air', 'bubbles', 'left', 'i', 'don', 't', 'like', 'it', 'when', 'droplets', 'of', 'water', 'make', 'only', 'a', 'part', 'of', 'my', 'feet', 'wet', 'only', 'to', 'let', 'me', 'realise', 'and', 'miss', 'the', 'comfort', 'of', 'dry', 'skin', 'and', 'scowl', 'at', 'the', 'linger', 'of', 'irritation', 'due', 'to', 'a', 'little', 'dampness', 'i', 'don', 't', 'like', 'it', 'when', 'i', 'have', 'to', 'keep', 'on', 'brushing', 'my', 'left', 'leg', 'against', 'my', 'right', 'to', 'flatten', 'the', 'spheres', 'of', 'water', 'and', 'repeat', 'it', 'with', 'the', 'right', 'i', 'just', 'realised', 'why', 'i', 'don', 't', 'like', 'drizzling', 'rains', 'eventually', 'when', 'i', 'have', 'to', 'get', 'out', 'of', 'the', 'water', 'i', 'give', 'up', 'my', 'fight', 'with', 'the', 'dirt', 'and', 'wear', 'those', 'damn', 'shoes', 'with', 'muddy', 'feet', 'those', 'are', 'the', 'times', 'i', 'miss', 'my', 'slippery', 'slippers', 'don', 't', 'let', 'my', 'socks', 'or', 'shoes', 'hear', 'me', 'say', 'that', 'they', 'do', 'not', 'know', 'that', 'sometimes', 'i', 'keep', 'a', 'back', 'up', 'pair', 'of', 'red', 'flip', 'flops', 'for', 'such', 'scenarios', 'does', 'this', 'make', 'me', 'a', 'slipper', 'person', 'i', 'guess', 'i', 'am', 'a', 'slipper', 'person', 'when', 'my', 'feet', 'are', 'ankle', 'deep', 'in', 'mud', 'so', 'that', 'there', 'is', 'no', 'place', 'for', 'me', 'to', 'complain', 'no', 'alternative', 'no', 'uneasy', 'half', 'done', 'feeling', 'otherwise', 'not', 'much', 'of', 'a', 'slipper', 'person', 'i', 'am', 'a', 'person', 'who', 'likes', 'symmetry', 'all', 'in', 'or', 'none', 'at', 'all', 'it', 's', 'difficult', 'being', 'me', 'in', 'this', 'world', 'with', 'its', 'shades', 'of', 'grey', 'but', 'then', 'my', 'favourite', 'colour', 'is', 'red', 'and', 'thankfully', 'it', 'covers', 'the', 'entire', 'spectrum', 'all', 'i', 'need', 'is', 'an', 'emotion', 'and', 'the', 'rest', 'is', 'taken', 'care', 'of', 'thank', 'you', 'for', 'being', 'the', 'listener', 'you', 'are', 'this', 'has', 'been', 'a', 'selfish', 'post', 'i', 'used', 'your', 'letter', 'for', 'my', 'sense', 'of', 'clarity', 'you', 'always', 'make', 'me', 'reflect', 'and', 'dig', 'deep', 'i', 'can', 'finally', 'sleep', 'now', 'goodnight']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCD8nxztgOvV"
      },
      "source": [
        "## **Importing StopWords**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btDSLdaphP_U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "2a1f70d6-5bf3-4c3d-a83d-f639fb04885f"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34knVtvi7X5T"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47JjPle47bHz"
      },
      "source": [
        "### **Remove StopWords from given tokens**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0MEPHp0fCw2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b5da055b-67fb-4e44-e356-a64c661dc0a7"
      },
      "source": [
        "for i in tokens:\n",
        "    if i in stop_words:\n",
        "        tokens.remove(i)\n",
        "print(\"After removing Stop Words: \",tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "After removing Stop Words:  ['must', 'honest', 'was', 'go', 'sleep', 'opened', 'mail', 'read', 'letter', 'wide', 'awake', 'sitting', 'upright', 'made', 'question', 'preferences', 'shoes', 'slippers', 'patient', 'need', 'proper', 'peaceful', 'sleep', 'let', 'sort', 'am', 'shoe', 'person', 'correction', 'am', 'person', 'obsessed', 'dry', 'dust', 'free', 'feet', 'whatever', 'helps', 'keep', 'grip', 'walk', 'posture', 'spite', 'profusely', 'sweaty', 'feet', 'am', 'person', 'whatever', 'keeps', 'grainy', 'pokey', 'sensation', 'soil', 'sand', 'parts', 'skin', 'away', 'am', 'person', 'guess', 'am', 'shoe', 'person', 'loyal', 'whole', 'feet', 'making', 'parts', 'lying', 'exposed', 'parts', 'covered', 'without', 'symmetry', 'am', 'also', 'cotton', 'sock', 'person', 'preferably', 'red', 'sometimes', 'am', 'clean', 'matte', 'anti', 'slippery', 'floor', 'person', 'basically', 'am', 'person', 'issues', 'really', 'liked', 'host', 'guest', 'theory', 'travelling', 'we', 'get', 'home', 'we', 'travel', 'home', 'expands', 'we', 'step', 'foot', 'place', 'engulfing', 'into', 'comfort', 'zone', 'thing', 'wear', 'socks', 'time', 'house', 'open', 'go', 'bed', 'replacing', 'sock', 'comforter', 'guess', 'need', 'comfort', 'zone', 'close', 'maybe', 'mine', 'restricted', 'skin', 'much', 'doesn', 'even', 'include', 'own', 'home', 'travel', 'like', 'wearing', 'shoes', 'firm', 'grip', 'myself', 'dust', 'free', 'protected', 'face', 'situations', 'open', 'want', 'usually', 'wrinkle', 'nose', 'doesn', 'get', 'better', 'wear', 'shoes', 'dirty', 'feet', 'take', 'handkerchief', 'imagine', 'my', 'situation', 'beach', 'hill', 'stream', 'water', 'feels', 'soothing', 'my', 'sweaty', 'feet', 'removes', 'dust', 'attract', 'walk', 'sand', 'let', 'irritate', 'times', 'always', 'ocean', 'the', 'river', 'my', 'side', 'like', 'my', 'bare', 'feet', 'drowning', 'air', 'bubbles', 'left', 'like', 'when', 'droplets', 'water', 'make', 'a', 'part', 'my', 'feet', 'wet', 'let', 'realise', 'miss', 'the', 'comfort', 'dry', 'skin', 'scowl', 'the', 'linger', 'irritation', 'due', 'to', 'a', 'little', 'dampness', 'don', 't', 'like', 'when', 'to', 'keep', 'brushing', 'my', 'left', 'leg', 'my', 'right', 'to', 'flatten', 'the', 'spheres', 'water', 'repeat', 'it', 'the', 'right', 'i', 'just', 'realised', 'i', 'don', 't', 'like', 'drizzling', 'rains', 'eventually', 'when', 'i', 'have', 'to', 'get', 'out', 'the', 'water', 'i', 'give', 'my', 'fight', 'the', 'dirt', 'wear', 'damn', 'shoes', 'with', 'muddy', 'feet', 'those', 'the', 'times', 'i', 'miss', 'my', 'slippery', 'slippers', 'don', 't', 'let', 'my', 'socks', 'shoes', 'hear', 'say', 'they', 'not', 'know', 'that', 'sometimes', 'i', 'keep', 'a', 'back', 'pair', 'red', 'flip', 'flops', 'such', 'scenarios', 'make', 'a', 'slipper', 'person', 'i', 'guess', 'i', 'am', 'a', 'slipper', 'person', 'when', 'my', 'feet', 'are', 'ankle', 'deep', 'mud', 'that', 'place', 'me', 'to', 'complain', 'alternative', 'no', 'uneasy', 'half', 'done', 'feeling', 'otherwise', 'not', 'much', 'a', 'slipper', 'person', 'i', 'am', 'a', 'person', 'likes', 'symmetry', 'in', 'none', 'it', 's', 'difficult', 'me', 'in', 'this', 'world', 'with', 'its', 'shades', 'of', 'grey', 'then', 'my', 'favourite', 'colour', 'red', 'thankfully', 'it', 'covers', 'the', 'entire', 'spectrum', 'all', 'i', 'need', 'an', 'emotion', 'the', 'rest', 'is', 'taken', 'care', 'of', 'thank', 'the', 'listener', 'you', 'are', 'this', 'has', 'a', 'selfish', 'post', 'i', 'used', 'letter', 'for', 'my', 'sense', 'of', 'clarity', 'you', 'always', 'make', 'me', 'reflect', 'and', 'dig', 'deep', 'i', 'can', 'finally', 'sleep', 'goodnight']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR0X_Q2hc5n1"
      },
      "source": [
        "## **Count word frequency**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4J-JM0MXc4c-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d7ae2984-3755-4ea0-f1cf-eb3354a4fd32"
      },
      "source": [
        "f = nltk.FreqDist(tokens)\n",
        "for key,val in f.items():\n",
        "    print (str(key) + ':' + str(val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "must:1\n",
            "honest:1\n",
            "was:1\n",
            "go:2\n",
            "sleep:3\n",
            "opened:1\n",
            "mail:1\n",
            "read:1\n",
            "letter:2\n",
            "wide:1\n",
            "awake:1\n",
            "sitting:1\n",
            "upright:1\n",
            "made:1\n",
            "question:1\n",
            "preferences:1\n",
            "shoes:5\n",
            "slippers:2\n",
            "patient:1\n",
            "need:3\n",
            "proper:1\n",
            "peaceful:1\n",
            "let:4\n",
            "sort:1\n",
            "am:10\n",
            "shoe:2\n",
            "person:12\n",
            "correction:1\n",
            "obsessed:1\n",
            "dry:2\n",
            "dust:3\n",
            "free:2\n",
            "feet:9\n",
            "whatever:2\n",
            "helps:1\n",
            "keep:3\n",
            "grip:2\n",
            "walk:2\n",
            "posture:1\n",
            "spite:1\n",
            "profusely:1\n",
            "sweaty:2\n",
            "keeps:1\n",
            "grainy:1\n",
            "pokey:1\n",
            "sensation:1\n",
            "soil:1\n",
            "sand:2\n",
            "parts:3\n",
            "skin:3\n",
            "away:1\n",
            "guess:3\n",
            "loyal:1\n",
            "whole:1\n",
            "making:1\n",
            "lying:1\n",
            "exposed:1\n",
            "covered:1\n",
            "without:1\n",
            "symmetry:2\n",
            "also:1\n",
            "cotton:1\n",
            "sock:2\n",
            "preferably:1\n",
            "red:3\n",
            "sometimes:2\n",
            "clean:1\n",
            "matte:1\n",
            "anti:1\n",
            "slippery:2\n",
            "floor:1\n",
            "basically:1\n",
            "issues:1\n",
            "really:1\n",
            "liked:1\n",
            "host:1\n",
            "guest:1\n",
            "theory:1\n",
            "travelling:1\n",
            "we:3\n",
            "get:3\n",
            "home:3\n",
            "travel:2\n",
            "expands:1\n",
            "step:1\n",
            "foot:1\n",
            "place:2\n",
            "engulfing:1\n",
            "into:1\n",
            "comfort:3\n",
            "zone:2\n",
            "thing:1\n",
            "wear:3\n",
            "socks:2\n",
            "time:1\n",
            "house:1\n",
            "open:2\n",
            "bed:1\n",
            "replacing:1\n",
            "comforter:1\n",
            "close:1\n",
            "maybe:1\n",
            "mine:1\n",
            "restricted:1\n",
            "much:2\n",
            "doesn:2\n",
            "even:1\n",
            "include:1\n",
            "own:1\n",
            "like:5\n",
            "wearing:1\n",
            "firm:1\n",
            "myself:1\n",
            "protected:1\n",
            "face:1\n",
            "situations:1\n",
            "want:1\n",
            "usually:1\n",
            "wrinkle:1\n",
            "nose:1\n",
            "better:1\n",
            "dirty:1\n",
            "take:1\n",
            "handkerchief:1\n",
            "imagine:1\n",
            "my:13\n",
            "situation:1\n",
            "beach:1\n",
            "hill:1\n",
            "stream:1\n",
            "water:4\n",
            "feels:1\n",
            "soothing:1\n",
            "removes:1\n",
            "attract:1\n",
            "irritate:1\n",
            "times:2\n",
            "always:2\n",
            "ocean:1\n",
            "the:11\n",
            "river:1\n",
            "side:1\n",
            "bare:1\n",
            "drowning:1\n",
            "air:1\n",
            "bubbles:1\n",
            "left:2\n",
            "when:4\n",
            "droplets:1\n",
            "make:3\n",
            "a:8\n",
            "part:1\n",
            "wet:1\n",
            "realise:1\n",
            "miss:2\n",
            "scowl:1\n",
            "linger:1\n",
            "irritation:1\n",
            "due:1\n",
            "to:5\n",
            "little:1\n",
            "dampness:1\n",
            "don:3\n",
            "t:3\n",
            "brushing:1\n",
            "leg:1\n",
            "right:2\n",
            "flatten:1\n",
            "spheres:1\n",
            "repeat:1\n",
            "it:3\n",
            "i:12\n",
            "just:1\n",
            "realised:1\n",
            "drizzling:1\n",
            "rains:1\n",
            "eventually:1\n",
            "have:1\n",
            "out:1\n",
            "give:1\n",
            "fight:1\n",
            "dirt:1\n",
            "damn:1\n",
            "with:2\n",
            "muddy:1\n",
            "those:1\n",
            "hear:1\n",
            "say:1\n",
            "they:1\n",
            "not:2\n",
            "know:1\n",
            "that:2\n",
            "back:1\n",
            "pair:1\n",
            "flip:1\n",
            "flops:1\n",
            "such:1\n",
            "scenarios:1\n",
            "slipper:3\n",
            "are:2\n",
            "ankle:1\n",
            "deep:2\n",
            "mud:1\n",
            "me:3\n",
            "complain:1\n",
            "alternative:1\n",
            "no:1\n",
            "uneasy:1\n",
            "half:1\n",
            "done:1\n",
            "feeling:1\n",
            "otherwise:1\n",
            "likes:1\n",
            "in:2\n",
            "none:1\n",
            "s:1\n",
            "difficult:1\n",
            "this:2\n",
            "world:1\n",
            "its:1\n",
            "shades:1\n",
            "of:3\n",
            "grey:1\n",
            "then:1\n",
            "favourite:1\n",
            "colour:1\n",
            "thankfully:1\n",
            "covers:1\n",
            "entire:1\n",
            "spectrum:1\n",
            "all:1\n",
            "an:1\n",
            "emotion:1\n",
            "rest:1\n",
            "is:1\n",
            "taken:1\n",
            "care:1\n",
            "thank:1\n",
            "listener:1\n",
            "you:2\n",
            "has:1\n",
            "selfish:1\n",
            "post:1\n",
            "used:1\n",
            "for:1\n",
            "sense:1\n",
            "clarity:1\n",
            "reflect:1\n",
            "and:1\n",
            "dig:1\n",
            "can:1\n",
            "finally:1\n",
            "goodnight:1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z29kKyMDQrAb"
      },
      "source": [
        "# **Stemming**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "curTvZcoOqS9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6d7520dc-0ffc-4159-9a7a-6321a3a08f25"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "p = PorterStemmer()\n",
        "for i in tokens:\n",
        "    print( i , \" : \",p.stem(i))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "must  :  must\n",
            "honest  :  honest\n",
            "was  :  wa\n",
            "go  :  go\n",
            "sleep  :  sleep\n",
            "opened  :  open\n",
            "mail  :  mail\n",
            "read  :  read\n",
            "letter  :  letter\n",
            "wide  :  wide\n",
            "awake  :  awak\n",
            "sitting  :  sit\n",
            "upright  :  upright\n",
            "made  :  made\n",
            "question  :  question\n",
            "preferences  :  prefer\n",
            "shoes  :  shoe\n",
            "slippers  :  slipper\n",
            "patient  :  patient\n",
            "need  :  need\n",
            "proper  :  proper\n",
            "peaceful  :  peac\n",
            "sleep  :  sleep\n",
            "let  :  let\n",
            "sort  :  sort\n",
            "am  :  am\n",
            "shoe  :  shoe\n",
            "person  :  person\n",
            "correction  :  correct\n",
            "am  :  am\n",
            "person  :  person\n",
            "obsessed  :  obsess\n",
            "dry  :  dri\n",
            "dust  :  dust\n",
            "free  :  free\n",
            "feet  :  feet\n",
            "whatever  :  whatev\n",
            "helps  :  help\n",
            "keep  :  keep\n",
            "grip  :  grip\n",
            "walk  :  walk\n",
            "posture  :  postur\n",
            "spite  :  spite\n",
            "profusely  :  profus\n",
            "sweaty  :  sweati\n",
            "feet  :  feet\n",
            "am  :  am\n",
            "person  :  person\n",
            "whatever  :  whatev\n",
            "keeps  :  keep\n",
            "grainy  :  graini\n",
            "pokey  :  pokey\n",
            "sensation  :  sensat\n",
            "soil  :  soil\n",
            "sand  :  sand\n",
            "parts  :  part\n",
            "skin  :  skin\n",
            "away  :  away\n",
            "am  :  am\n",
            "person  :  person\n",
            "guess  :  guess\n",
            "am  :  am\n",
            "shoe  :  shoe\n",
            "person  :  person\n",
            "loyal  :  loyal\n",
            "whole  :  whole\n",
            "feet  :  feet\n",
            "making  :  make\n",
            "parts  :  part\n",
            "lying  :  lie\n",
            "exposed  :  expos\n",
            "parts  :  part\n",
            "covered  :  cover\n",
            "without  :  without\n",
            "symmetry  :  symmetri\n",
            "am  :  am\n",
            "also  :  also\n",
            "cotton  :  cotton\n",
            "sock  :  sock\n",
            "person  :  person\n",
            "preferably  :  prefer\n",
            "red  :  red\n",
            "sometimes  :  sometim\n",
            "am  :  am\n",
            "clean  :  clean\n",
            "matte  :  matt\n",
            "anti  :  anti\n",
            "slippery  :  slipperi\n",
            "floor  :  floor\n",
            "person  :  person\n",
            "basically  :  basic\n",
            "am  :  am\n",
            "person  :  person\n",
            "issues  :  issu\n",
            "really  :  realli\n",
            "liked  :  like\n",
            "host  :  host\n",
            "guest  :  guest\n",
            "theory  :  theori\n",
            "travelling  :  travel\n",
            "we  :  we\n",
            "get  :  get\n",
            "home  :  home\n",
            "we  :  we\n",
            "travel  :  travel\n",
            "home  :  home\n",
            "expands  :  expand\n",
            "we  :  we\n",
            "step  :  step\n",
            "foot  :  foot\n",
            "place  :  place\n",
            "engulfing  :  engulf\n",
            "into  :  into\n",
            "comfort  :  comfort\n",
            "zone  :  zone\n",
            "thing  :  thing\n",
            "wear  :  wear\n",
            "socks  :  sock\n",
            "time  :  time\n",
            "house  :  hous\n",
            "open  :  open\n",
            "go  :  go\n",
            "bed  :  bed\n",
            "replacing  :  replac\n",
            "sock  :  sock\n",
            "comforter  :  comfort\n",
            "guess  :  guess\n",
            "need  :  need\n",
            "comfort  :  comfort\n",
            "zone  :  zone\n",
            "close  :  close\n",
            "maybe  :  mayb\n",
            "mine  :  mine\n",
            "restricted  :  restrict\n",
            "skin  :  skin\n",
            "much  :  much\n",
            "doesn  :  doesn\n",
            "even  :  even\n",
            "include  :  includ\n",
            "own  :  own\n",
            "home  :  home\n",
            "travel  :  travel\n",
            "like  :  like\n",
            "wearing  :  wear\n",
            "shoes  :  shoe\n",
            "firm  :  firm\n",
            "grip  :  grip\n",
            "myself  :  myself\n",
            "dust  :  dust\n",
            "free  :  free\n",
            "protected  :  protect\n",
            "face  :  face\n",
            "situations  :  situat\n",
            "open  :  open\n",
            "want  :  want\n",
            "usually  :  usual\n",
            "wrinkle  :  wrinkl\n",
            "nose  :  nose\n",
            "doesn  :  doesn\n",
            "get  :  get\n",
            "better  :  better\n",
            "wear  :  wear\n",
            "shoes  :  shoe\n",
            "dirty  :  dirti\n",
            "feet  :  feet\n",
            "take  :  take\n",
            "handkerchief  :  handkerchief\n",
            "imagine  :  imagin\n",
            "my  :  my\n",
            "situation  :  situat\n",
            "beach  :  beach\n",
            "hill  :  hill\n",
            "stream  :  stream\n",
            "water  :  water\n",
            "feels  :  feel\n",
            "soothing  :  sooth\n",
            "my  :  my\n",
            "sweaty  :  sweati\n",
            "feet  :  feet\n",
            "removes  :  remov\n",
            "dust  :  dust\n",
            "attract  :  attract\n",
            "walk  :  walk\n",
            "sand  :  sand\n",
            "let  :  let\n",
            "irritate  :  irrit\n",
            "times  :  time\n",
            "always  :  alway\n",
            "ocean  :  ocean\n",
            "the  :  the\n",
            "river  :  river\n",
            "my  :  my\n",
            "side  :  side\n",
            "like  :  like\n",
            "my  :  my\n",
            "bare  :  bare\n",
            "feet  :  feet\n",
            "drowning  :  drown\n",
            "air  :  air\n",
            "bubbles  :  bubbl\n",
            "left  :  left\n",
            "like  :  like\n",
            "when  :  when\n",
            "droplets  :  droplet\n",
            "water  :  water\n",
            "make  :  make\n",
            "a  :  a\n",
            "part  :  part\n",
            "my  :  my\n",
            "feet  :  feet\n",
            "wet  :  wet\n",
            "let  :  let\n",
            "realise  :  realis\n",
            "miss  :  miss\n",
            "the  :  the\n",
            "comfort  :  comfort\n",
            "dry  :  dri\n",
            "skin  :  skin\n",
            "scowl  :  scowl\n",
            "the  :  the\n",
            "linger  :  linger\n",
            "irritation  :  irrit\n",
            "due  :  due\n",
            "to  :  to\n",
            "a  :  a\n",
            "little  :  littl\n",
            "dampness  :  damp\n",
            "don  :  don\n",
            "t  :  t\n",
            "like  :  like\n",
            "when  :  when\n",
            "to  :  to\n",
            "keep  :  keep\n",
            "brushing  :  brush\n",
            "my  :  my\n",
            "left  :  left\n",
            "leg  :  leg\n",
            "my  :  my\n",
            "right  :  right\n",
            "to  :  to\n",
            "flatten  :  flatten\n",
            "the  :  the\n",
            "spheres  :  sphere\n",
            "water  :  water\n",
            "repeat  :  repeat\n",
            "it  :  it\n",
            "the  :  the\n",
            "right  :  right\n",
            "i  :  i\n",
            "just  :  just\n",
            "realised  :  realis\n",
            "i  :  i\n",
            "don  :  don\n",
            "t  :  t\n",
            "like  :  like\n",
            "drizzling  :  drizzl\n",
            "rains  :  rain\n",
            "eventually  :  eventu\n",
            "when  :  when\n",
            "i  :  i\n",
            "have  :  have\n",
            "to  :  to\n",
            "get  :  get\n",
            "out  :  out\n",
            "the  :  the\n",
            "water  :  water\n",
            "i  :  i\n",
            "give  :  give\n",
            "my  :  my\n",
            "fight  :  fight\n",
            "the  :  the\n",
            "dirt  :  dirt\n",
            "wear  :  wear\n",
            "damn  :  damn\n",
            "shoes  :  shoe\n",
            "with  :  with\n",
            "muddy  :  muddi\n",
            "feet  :  feet\n",
            "those  :  those\n",
            "the  :  the\n",
            "times  :  time\n",
            "i  :  i\n",
            "miss  :  miss\n",
            "my  :  my\n",
            "slippery  :  slipperi\n",
            "slippers  :  slipper\n",
            "don  :  don\n",
            "t  :  t\n",
            "let  :  let\n",
            "my  :  my\n",
            "socks  :  sock\n",
            "shoes  :  shoe\n",
            "hear  :  hear\n",
            "say  :  say\n",
            "they  :  they\n",
            "not  :  not\n",
            "know  :  know\n",
            "that  :  that\n",
            "sometimes  :  sometim\n",
            "i  :  i\n",
            "keep  :  keep\n",
            "a  :  a\n",
            "back  :  back\n",
            "pair  :  pair\n",
            "red  :  red\n",
            "flip  :  flip\n",
            "flops  :  flop\n",
            "such  :  such\n",
            "scenarios  :  scenario\n",
            "make  :  make\n",
            "a  :  a\n",
            "slipper  :  slipper\n",
            "person  :  person\n",
            "i  :  i\n",
            "guess  :  guess\n",
            "i  :  i\n",
            "am  :  am\n",
            "a  :  a\n",
            "slipper  :  slipper\n",
            "person  :  person\n",
            "when  :  when\n",
            "my  :  my\n",
            "feet  :  feet\n",
            "are  :  are\n",
            "ankle  :  ankl\n",
            "deep  :  deep\n",
            "mud  :  mud\n",
            "that  :  that\n",
            "place  :  place\n",
            "me  :  me\n",
            "to  :  to\n",
            "complain  :  complain\n",
            "alternative  :  altern\n",
            "no  :  no\n",
            "uneasy  :  uneasi\n",
            "half  :  half\n",
            "done  :  done\n",
            "feeling  :  feel\n",
            "otherwise  :  otherwis\n",
            "not  :  not\n",
            "much  :  much\n",
            "a  :  a\n",
            "slipper  :  slipper\n",
            "person  :  person\n",
            "i  :  i\n",
            "am  :  am\n",
            "a  :  a\n",
            "person  :  person\n",
            "likes  :  like\n",
            "symmetry  :  symmetri\n",
            "in  :  in\n",
            "none  :  none\n",
            "it  :  it\n",
            "s  :  s\n",
            "difficult  :  difficult\n",
            "me  :  me\n",
            "in  :  in\n",
            "this  :  thi\n",
            "world  :  world\n",
            "with  :  with\n",
            "its  :  it\n",
            "shades  :  shade\n",
            "of  :  of\n",
            "grey  :  grey\n",
            "then  :  then\n",
            "my  :  my\n",
            "favourite  :  favourit\n",
            "colour  :  colour\n",
            "red  :  red\n",
            "thankfully  :  thank\n",
            "it  :  it\n",
            "covers  :  cover\n",
            "the  :  the\n",
            "entire  :  entir\n",
            "spectrum  :  spectrum\n",
            "all  :  all\n",
            "i  :  i\n",
            "need  :  need\n",
            "an  :  an\n",
            "emotion  :  emot\n",
            "the  :  the\n",
            "rest  :  rest\n",
            "is  :  is\n",
            "taken  :  taken\n",
            "care  :  care\n",
            "of  :  of\n",
            "thank  :  thank\n",
            "the  :  the\n",
            "listener  :  listen\n",
            "you  :  you\n",
            "are  :  are\n",
            "this  :  thi\n",
            "has  :  ha\n",
            "a  :  a\n",
            "selfish  :  selfish\n",
            "post  :  post\n",
            "i  :  i\n",
            "used  :  use\n",
            "letter  :  letter\n",
            "for  :  for\n",
            "my  :  my\n",
            "sense  :  sens\n",
            "of  :  of\n",
            "clarity  :  clariti\n",
            "you  :  you\n",
            "always  :  alway\n",
            "make  :  make\n",
            "me  :  me\n",
            "reflect  :  reflect\n",
            "and  :  and\n",
            "dig  :  dig\n",
            "deep  :  deep\n",
            "i  :  i\n",
            "can  :  can\n",
            "finally  :  final\n",
            "sleep  :  sleep\n",
            "goodnight  :  goodnight\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sy5hRmONQ2Dd"
      },
      "source": [
        "# **Lemmatization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XchYaKQZTuFa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "c46f8e5e-1f5e-4cd1-dc54-6ccd77fb14eb"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UahIf8KAQdyP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "201cfa6e-25be-4aa7-9926-a4860b365b44"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemma = WordNetLemmatizer()\n",
        "\n",
        "for i in tokens:\n",
        "    print(\"Lemma for {} is {}\".format(i,wordnet_lemma.lemmatize(i)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lemma for must is must\n",
            "Lemma for honest is honest\n",
            "Lemma for was is wa\n",
            "Lemma for go is go\n",
            "Lemma for sleep is sleep\n",
            "Lemma for opened is opened\n",
            "Lemma for mail is mail\n",
            "Lemma for read is read\n",
            "Lemma for letter is letter\n",
            "Lemma for wide is wide\n",
            "Lemma for awake is awake\n",
            "Lemma for sitting is sitting\n",
            "Lemma for upright is upright\n",
            "Lemma for made is made\n",
            "Lemma for question is question\n",
            "Lemma for preferences is preference\n",
            "Lemma for shoes is shoe\n",
            "Lemma for slippers is slipper\n",
            "Lemma for patient is patient\n",
            "Lemma for need is need\n",
            "Lemma for proper is proper\n",
            "Lemma for peaceful is peaceful\n",
            "Lemma for sleep is sleep\n",
            "Lemma for let is let\n",
            "Lemma for sort is sort\n",
            "Lemma for am is am\n",
            "Lemma for shoe is shoe\n",
            "Lemma for person is person\n",
            "Lemma for correction is correction\n",
            "Lemma for am is am\n",
            "Lemma for person is person\n",
            "Lemma for obsessed is obsessed\n",
            "Lemma for dry is dry\n",
            "Lemma for dust is dust\n",
            "Lemma for free is free\n",
            "Lemma for feet is foot\n",
            "Lemma for whatever is whatever\n",
            "Lemma for helps is help\n",
            "Lemma for keep is keep\n",
            "Lemma for grip is grip\n",
            "Lemma for walk is walk\n",
            "Lemma for posture is posture\n",
            "Lemma for spite is spite\n",
            "Lemma for profusely is profusely\n",
            "Lemma for sweaty is sweaty\n",
            "Lemma for feet is foot\n",
            "Lemma for am is am\n",
            "Lemma for person is person\n",
            "Lemma for whatever is whatever\n",
            "Lemma for keeps is keep\n",
            "Lemma for grainy is grainy\n",
            "Lemma for pokey is pokey\n",
            "Lemma for sensation is sensation\n",
            "Lemma for soil is soil\n",
            "Lemma for sand is sand\n",
            "Lemma for parts is part\n",
            "Lemma for skin is skin\n",
            "Lemma for away is away\n",
            "Lemma for am is am\n",
            "Lemma for person is person\n",
            "Lemma for guess is guess\n",
            "Lemma for am is am\n",
            "Lemma for shoe is shoe\n",
            "Lemma for person is person\n",
            "Lemma for loyal is loyal\n",
            "Lemma for whole is whole\n",
            "Lemma for feet is foot\n",
            "Lemma for making is making\n",
            "Lemma for parts is part\n",
            "Lemma for lying is lying\n",
            "Lemma for exposed is exposed\n",
            "Lemma for parts is part\n",
            "Lemma for covered is covered\n",
            "Lemma for without is without\n",
            "Lemma for symmetry is symmetry\n",
            "Lemma for am is am\n",
            "Lemma for also is also\n",
            "Lemma for cotton is cotton\n",
            "Lemma for sock is sock\n",
            "Lemma for person is person\n",
            "Lemma for preferably is preferably\n",
            "Lemma for red is red\n",
            "Lemma for sometimes is sometimes\n",
            "Lemma for am is am\n",
            "Lemma for clean is clean\n",
            "Lemma for matte is matte\n",
            "Lemma for anti is anti\n",
            "Lemma for slippery is slippery\n",
            "Lemma for floor is floor\n",
            "Lemma for person is person\n",
            "Lemma for basically is basically\n",
            "Lemma for am is am\n",
            "Lemma for person is person\n",
            "Lemma for issues is issue\n",
            "Lemma for really is really\n",
            "Lemma for liked is liked\n",
            "Lemma for host is host\n",
            "Lemma for guest is guest\n",
            "Lemma for theory is theory\n",
            "Lemma for travelling is travelling\n",
            "Lemma for we is we\n",
            "Lemma for get is get\n",
            "Lemma for home is home\n",
            "Lemma for we is we\n",
            "Lemma for travel is travel\n",
            "Lemma for home is home\n",
            "Lemma for expands is expands\n",
            "Lemma for we is we\n",
            "Lemma for step is step\n",
            "Lemma for foot is foot\n",
            "Lemma for place is place\n",
            "Lemma for engulfing is engulfing\n",
            "Lemma for into is into\n",
            "Lemma for comfort is comfort\n",
            "Lemma for zone is zone\n",
            "Lemma for thing is thing\n",
            "Lemma for wear is wear\n",
            "Lemma for socks is sock\n",
            "Lemma for time is time\n",
            "Lemma for house is house\n",
            "Lemma for open is open\n",
            "Lemma for go is go\n",
            "Lemma for bed is bed\n",
            "Lemma for replacing is replacing\n",
            "Lemma for sock is sock\n",
            "Lemma for comforter is comforter\n",
            "Lemma for guess is guess\n",
            "Lemma for need is need\n",
            "Lemma for comfort is comfort\n",
            "Lemma for zone is zone\n",
            "Lemma for close is close\n",
            "Lemma for maybe is maybe\n",
            "Lemma for mine is mine\n",
            "Lemma for restricted is restricted\n",
            "Lemma for skin is skin\n",
            "Lemma for much is much\n",
            "Lemma for doesn is doesn\n",
            "Lemma for even is even\n",
            "Lemma for include is include\n",
            "Lemma for own is own\n",
            "Lemma for home is home\n",
            "Lemma for travel is travel\n",
            "Lemma for like is like\n",
            "Lemma for wearing is wearing\n",
            "Lemma for shoes is shoe\n",
            "Lemma for firm is firm\n",
            "Lemma for grip is grip\n",
            "Lemma for myself is myself\n",
            "Lemma for dust is dust\n",
            "Lemma for free is free\n",
            "Lemma for protected is protected\n",
            "Lemma for face is face\n",
            "Lemma for situations is situation\n",
            "Lemma for open is open\n",
            "Lemma for want is want\n",
            "Lemma for usually is usually\n",
            "Lemma for wrinkle is wrinkle\n",
            "Lemma for nose is nose\n",
            "Lemma for doesn is doesn\n",
            "Lemma for get is get\n",
            "Lemma for better is better\n",
            "Lemma for wear is wear\n",
            "Lemma for shoes is shoe\n",
            "Lemma for dirty is dirty\n",
            "Lemma for feet is foot\n",
            "Lemma for take is take\n",
            "Lemma for handkerchief is handkerchief\n",
            "Lemma for imagine is imagine\n",
            "Lemma for my is my\n",
            "Lemma for situation is situation\n",
            "Lemma for beach is beach\n",
            "Lemma for hill is hill\n",
            "Lemma for stream is stream\n",
            "Lemma for water is water\n",
            "Lemma for feels is feel\n",
            "Lemma for soothing is soothing\n",
            "Lemma for my is my\n",
            "Lemma for sweaty is sweaty\n",
            "Lemma for feet is foot\n",
            "Lemma for removes is remove\n",
            "Lemma for dust is dust\n",
            "Lemma for attract is attract\n",
            "Lemma for walk is walk\n",
            "Lemma for sand is sand\n",
            "Lemma for let is let\n",
            "Lemma for irritate is irritate\n",
            "Lemma for times is time\n",
            "Lemma for always is always\n",
            "Lemma for ocean is ocean\n",
            "Lemma for the is the\n",
            "Lemma for river is river\n",
            "Lemma for my is my\n",
            "Lemma for side is side\n",
            "Lemma for like is like\n",
            "Lemma for my is my\n",
            "Lemma for bare is bare\n",
            "Lemma for feet is foot\n",
            "Lemma for drowning is drowning\n",
            "Lemma for air is air\n",
            "Lemma for bubbles is bubble\n",
            "Lemma for left is left\n",
            "Lemma for like is like\n",
            "Lemma for when is when\n",
            "Lemma for droplets is droplet\n",
            "Lemma for water is water\n",
            "Lemma for make is make\n",
            "Lemma for a is a\n",
            "Lemma for part is part\n",
            "Lemma for my is my\n",
            "Lemma for feet is foot\n",
            "Lemma for wet is wet\n",
            "Lemma for let is let\n",
            "Lemma for realise is realise\n",
            "Lemma for miss is miss\n",
            "Lemma for the is the\n",
            "Lemma for comfort is comfort\n",
            "Lemma for dry is dry\n",
            "Lemma for skin is skin\n",
            "Lemma for scowl is scowl\n",
            "Lemma for the is the\n",
            "Lemma for linger is linger\n",
            "Lemma for irritation is irritation\n",
            "Lemma for due is due\n",
            "Lemma for to is to\n",
            "Lemma for a is a\n",
            "Lemma for little is little\n",
            "Lemma for dampness is dampness\n",
            "Lemma for don is don\n",
            "Lemma for t is t\n",
            "Lemma for like is like\n",
            "Lemma for when is when\n",
            "Lemma for to is to\n",
            "Lemma for keep is keep\n",
            "Lemma for brushing is brushing\n",
            "Lemma for my is my\n",
            "Lemma for left is left\n",
            "Lemma for leg is leg\n",
            "Lemma for my is my\n",
            "Lemma for right is right\n",
            "Lemma for to is to\n",
            "Lemma for flatten is flatten\n",
            "Lemma for the is the\n",
            "Lemma for spheres is sphere\n",
            "Lemma for water is water\n",
            "Lemma for repeat is repeat\n",
            "Lemma for it is it\n",
            "Lemma for the is the\n",
            "Lemma for right is right\n",
            "Lemma for i is i\n",
            "Lemma for just is just\n",
            "Lemma for realised is realised\n",
            "Lemma for i is i\n",
            "Lemma for don is don\n",
            "Lemma for t is t\n",
            "Lemma for like is like\n",
            "Lemma for drizzling is drizzling\n",
            "Lemma for rains is rain\n",
            "Lemma for eventually is eventually\n",
            "Lemma for when is when\n",
            "Lemma for i is i\n",
            "Lemma for have is have\n",
            "Lemma for to is to\n",
            "Lemma for get is get\n",
            "Lemma for out is out\n",
            "Lemma for the is the\n",
            "Lemma for water is water\n",
            "Lemma for i is i\n",
            "Lemma for give is give\n",
            "Lemma for my is my\n",
            "Lemma for fight is fight\n",
            "Lemma for the is the\n",
            "Lemma for dirt is dirt\n",
            "Lemma for wear is wear\n",
            "Lemma for damn is damn\n",
            "Lemma for shoes is shoe\n",
            "Lemma for with is with\n",
            "Lemma for muddy is muddy\n",
            "Lemma for feet is foot\n",
            "Lemma for those is those\n",
            "Lemma for the is the\n",
            "Lemma for times is time\n",
            "Lemma for i is i\n",
            "Lemma for miss is miss\n",
            "Lemma for my is my\n",
            "Lemma for slippery is slippery\n",
            "Lemma for slippers is slipper\n",
            "Lemma for don is don\n",
            "Lemma for t is t\n",
            "Lemma for let is let\n",
            "Lemma for my is my\n",
            "Lemma for socks is sock\n",
            "Lemma for shoes is shoe\n",
            "Lemma for hear is hear\n",
            "Lemma for say is say\n",
            "Lemma for they is they\n",
            "Lemma for not is not\n",
            "Lemma for know is know\n",
            "Lemma for that is that\n",
            "Lemma for sometimes is sometimes\n",
            "Lemma for i is i\n",
            "Lemma for keep is keep\n",
            "Lemma for a is a\n",
            "Lemma for back is back\n",
            "Lemma for pair is pair\n",
            "Lemma for red is red\n",
            "Lemma for flip is flip\n",
            "Lemma for flops is flop\n",
            "Lemma for such is such\n",
            "Lemma for scenarios is scenario\n",
            "Lemma for make is make\n",
            "Lemma for a is a\n",
            "Lemma for slipper is slipper\n",
            "Lemma for person is person\n",
            "Lemma for i is i\n",
            "Lemma for guess is guess\n",
            "Lemma for i is i\n",
            "Lemma for am is am\n",
            "Lemma for a is a\n",
            "Lemma for slipper is slipper\n",
            "Lemma for person is person\n",
            "Lemma for when is when\n",
            "Lemma for my is my\n",
            "Lemma for feet is foot\n",
            "Lemma for are is are\n",
            "Lemma for ankle is ankle\n",
            "Lemma for deep is deep\n",
            "Lemma for mud is mud\n",
            "Lemma for that is that\n",
            "Lemma for place is place\n",
            "Lemma for me is me\n",
            "Lemma for to is to\n",
            "Lemma for complain is complain\n",
            "Lemma for alternative is alternative\n",
            "Lemma for no is no\n",
            "Lemma for uneasy is uneasy\n",
            "Lemma for half is half\n",
            "Lemma for done is done\n",
            "Lemma for feeling is feeling\n",
            "Lemma for otherwise is otherwise\n",
            "Lemma for not is not\n",
            "Lemma for much is much\n",
            "Lemma for a is a\n",
            "Lemma for slipper is slipper\n",
            "Lemma for person is person\n",
            "Lemma for i is i\n",
            "Lemma for am is am\n",
            "Lemma for a is a\n",
            "Lemma for person is person\n",
            "Lemma for likes is like\n",
            "Lemma for symmetry is symmetry\n",
            "Lemma for in is in\n",
            "Lemma for none is none\n",
            "Lemma for it is it\n",
            "Lemma for s is s\n",
            "Lemma for difficult is difficult\n",
            "Lemma for me is me\n",
            "Lemma for in is in\n",
            "Lemma for this is this\n",
            "Lemma for world is world\n",
            "Lemma for with is with\n",
            "Lemma for its is it\n",
            "Lemma for shades is shade\n",
            "Lemma for of is of\n",
            "Lemma for grey is grey\n",
            "Lemma for then is then\n",
            "Lemma for my is my\n",
            "Lemma for favourite is favourite\n",
            "Lemma for colour is colour\n",
            "Lemma for red is red\n",
            "Lemma for thankfully is thankfully\n",
            "Lemma for it is it\n",
            "Lemma for covers is cover\n",
            "Lemma for the is the\n",
            "Lemma for entire is entire\n",
            "Lemma for spectrum is spectrum\n",
            "Lemma for all is all\n",
            "Lemma for i is i\n",
            "Lemma for need is need\n",
            "Lemma for an is an\n",
            "Lemma for emotion is emotion\n",
            "Lemma for the is the\n",
            "Lemma for rest is rest\n",
            "Lemma for is is is\n",
            "Lemma for taken is taken\n",
            "Lemma for care is care\n",
            "Lemma for of is of\n",
            "Lemma for thank is thank\n",
            "Lemma for the is the\n",
            "Lemma for listener is listener\n",
            "Lemma for you is you\n",
            "Lemma for are is are\n",
            "Lemma for this is this\n",
            "Lemma for has is ha\n",
            "Lemma for a is a\n",
            "Lemma for selfish is selfish\n",
            "Lemma for post is post\n",
            "Lemma for i is i\n",
            "Lemma for used is used\n",
            "Lemma for letter is letter\n",
            "Lemma for for is for\n",
            "Lemma for my is my\n",
            "Lemma for sense is sense\n",
            "Lemma for of is of\n",
            "Lemma for clarity is clarity\n",
            "Lemma for you is you\n",
            "Lemma for always is always\n",
            "Lemma for make is make\n",
            "Lemma for me is me\n",
            "Lemma for reflect is reflect\n",
            "Lemma for and is and\n",
            "Lemma for dig is dig\n",
            "Lemma for deep is deep\n",
            "Lemma for i is i\n",
            "Lemma for can is can\n",
            "Lemma for finally is finally\n",
            "Lemma for sleep is sleep\n",
            "Lemma for goodnight is goodnight\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFObUzP6iWOH"
      },
      "source": [
        "# **Implementation of a Sentence Segmentation Algorithm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StNQlbBQgtpJ"
      },
      "source": [
        "def look_sentences(a_str, sub):\n",
        "    start = 0\n",
        "    while True:\n",
        "        start = a_str.find(sub, start)\n",
        "        if start == -1:\n",
        "            return\n",
        "        yield start\n",
        "        start += len(sub)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jz-i37YpgwlF"
      },
      "source": [
        "def sentence_end(para):\n",
        "    poss_end = []\n",
        "    sentence_enders = sentence_enders_list + [z + w for w in sentence_containers_list for z in sentence_enders_list]\n",
        "    for p in sentence_enders:\n",
        "        e_Indexs = list(look_sentences(para, p))\n",
        "        poss_end.extend(([] if not len(e_Indexs) else [[i, len(p)] for i in e_Indexs]))\n",
        "    if len(para) in [pe[0] + pe[1] for pe in poss_end]:\n",
        "        max_end_start = max([pe[0] for pe in poss_end])\n",
        "        poss_end = [pe for pe in poss_end if pe[0] != max_end_start]\n",
        "    poss_end = [pe[0] + pe[1] for pe in poss_end if sum(pe) > len(para) or (sum(pe) < len(para) and para[sum(pe)] == ' ')]\n",
        "    end = (-1 if not len(poss_end) else max(poss_end))\n",
        "    return end"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaMz94QbgFwg"
      },
      "source": [
        "def sentences(para):\n",
        "   end = True\n",
        "   sentences_list = []\n",
        "   while end > -1:\n",
        "       end = sentence_end(para)\n",
        "       if end > -1:\n",
        "           sentences_list.append(para[end:].strip())\n",
        "           para = para[:end]\n",
        "   sentences_list.append(para)\n",
        "   sentences_list.reverse()\n",
        "   while('' in sentences_list): \n",
        "       sentences_list.remove(\"\")\n",
        "   return sentences_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnNOSWSggG3c"
      },
      "source": [
        "sentence_enders_list = ['.', '.\\n', '!', '!\\n', '?', '?\\n','\\n']\n",
        "sentence_containers_list = ['}', ')', '\"', ']', \"'\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPdwhfkGgKAs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 860
        },
        "outputId": "6ebb022a-3dd7-4290-f161-fa5fbf1f4366"
      },
      "source": [
        "sentences(input_str)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i must be honest with you.',\n",
              " 'i was about to go to sleep before i opened my mail and read your letter.',\n",
              " 'now i am wide awake, sitting upright, because you made me question my preferences between shoes and slippers.',\n",
              " 'be patient with me.',\n",
              " 'i need proper peaceful sleep and let’s sort this out.',\n",
              " 'i am a shoe person.',\n",
              " 'correction: i am a person obsessed with dry, dust-free feet.',\n",
              " 'whatever helps me keep a grip on my walk and posture in spite of my profusely sweaty feet, i am that person.',\n",
              " 'whatever keeps the grainy, pokey sensation of soil or sand in parts of my skin away, i am that person.',\n",
              " 'i guess, i am a shoe person because it is loyal to my whole feet.',\n",
              " 'not making parts of it lying exposed and parts of it covered, without any symmetry.',\n",
              " 'i am also cotton sock person, preferably red.',\n",
              " 'sometimes, i am a clean matte (anti-slippery) floor person.',\n",
              " 'basically, i am a person with issues.',\n",
              " 'i really liked your host-guest theory of travelling, how we do not just get out of home when we travel, the home expands when we step foot at a place engulfing it into our comfort zone.',\n",
              " 'but the thing is i wear socks all the time in my house, and open them when i go to bed, replacing the sock with a comforter.',\n",
              " 'i guess i need that comfort zone close and maybe, mine is restricted to my own skin.',\n",
              " 'so much so, that it doesn’t even include my own home.',\n",
              " 'when i travel, i like wearing shoes, with a firm grip on myself, dust free, protected.',\n",
              " 'when i face situations where i have to open them and i don’t want to, i usually wrinkle my nose.',\n",
              " 'it doesn’t get better that i can’t wear those shoes again with a dirty feet.',\n",
              " 'i take a handkerchief.',\n",
              " 'imagine my situation at the beach or in a hill stream, when the water feels soothing to my sweaty feet and removes the dust, only to attract more of it when i walk on the sand.',\n",
              " 'i let it irritate me those times, because i always have the ocean and the river on my side.',\n",
              " 'i like my bare feet drowning with no air bubbles left.',\n",
              " 'i don’t like it when droplets of water make only a part of my feet wet, only to let me realise and miss the comfort of dry skin and scowl at the linger of irritation due to a little dampness.',\n",
              " 'i don’t like it when i have to keep on brushing my left leg against my right to flatten the spheres of water.',\n",
              " 'and repeat it with the right.',\n",
              " 'i just realised why i don’t like drizzling rains.',\n",
              " 'eventually, when i have to get out of the water, i give up my fight with the dirt and wear those damn shoes with muddy feet.',\n",
              " 'those are the times i miss my slippery slippers.',\n",
              " 'don’t let my socks or shoes hear me say that.',\n",
              " 'they do not know that sometimes i keep a back-up pair of red flip-flops for such scenarios.',\n",
              " 'does this make me a slipper person?',\n",
              " 'i guess i am a slipper person when my feet are ankle deep in mud, so that there is no place for me to complain.',\n",
              " 'no alternative.',\n",
              " 'no uneasy half-done feeling.',\n",
              " 'otherwise, not much of a slipper person.',\n",
              " 'i am a person who likes symmetry.',\n",
              " 'all in or none at all.',\n",
              " 'it’s difficult being me in this world with its shades of grey.',\n",
              " 'but then, my favourite colour is red and thankfully it covers the entire spectrum.',\n",
              " 'all i need is an emotion, and the rest is taken care of.',\n",
              " 'thank you for being the listener you are.',\n",
              " 'this has been a selfish post.',\n",
              " 'i used your letter for my sense of clarity.',\n",
              " 'you always make me reflect and dig deep.',\n",
              " 'i can finally sleep now.',\n",
              " 'goodnight.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    }
  ]
}